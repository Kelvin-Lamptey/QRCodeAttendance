{% extends "base.html" %}

{% block show_navbar %}{% endblock %}

{% block content %}
<style>
@media (max-width: 768px) {
    .camera-container {
        width: 100% !important;
        height: auto !important;
    }
    video, canvas {
        width: 100% !important;
        height: auto !important;
    }
}
</style>

<div class="max-w-2xl mx-auto bg-white shadow rounded-lg p-6">
    <h2 class="text-2xl font-bold mb-6">Mark Attendance for {{ session.name }}</h2>
    
    <div class="relative mb-6 camera-container" style="width: 640px; height: 480px; margin: 0 auto;">
        <video id="video" width="640" height="480" autoplay muted class="mx-auto border rounded-lg"></video>
        <canvas id="overlay" class="absolute top-0 left-0" width="640" height="480"></canvas>
    </div>
    
    <div id="status" class="text-center text-lg mb-4 p-2"></div>
    <div id="status2" class="text-center text-lg mb-4 p-2"></div>
    <div id="controls" class="text-center space-x-4 mt-4 relative z-10">
        <button id="startButton" class="bg-green-500 text-white px-4 py-2 rounded hover:bg-green-600">
            Start Camera
        </button>
        <button id="captureButton" class="bg-blue-500 text-white px-4 py-2 rounded hover:bg-blue-600" disabled>
            Mark Attendance
        </button>
    </div>
</div>

{% endblock %}

{% block scripts %}
<script src="{{ url_for('static', filename='js/face-recognition.js') }}"></script>
<script>
const video = document.getElementById('video');
const overlay = document.getElementById('overlay');
const status = document.getElementById('status');
const status2 = document.getElementById('status2');
const startButton = document.getElementById('startButton');
const captureButton = document.getElementById('captureButton');

let isProcessing = false;
let faceCheckInterval;

async function startCamera() {
    try {
        status.textContent = 'Initializing camera...';
        status.className = 'text-center text-lg mb-4 p-2 bg-yellow-100 text-yellow-700';
        
        console.log("Checking camera support...");
        if (!isCameraSupported()) {
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            
            if (isMobile) {
                // Specific message for mobile users
                if (window.location.protocol === 'http:') {
                    status.innerHTML = `
                        <strong>Camera access requires HTTPS on mobile devices.</strong><br>
                        Please access this application using a secure (HTTPS) connection or try using Chrome/Firefox on a desktop computer.
                    `;
                } else {
                    status.innerHTML = `
                        <strong>Camera not supported on this mobile browser.</strong><br>
                        Please try using Chrome, Firefox, or Safari (iOS).
                    `;
                }
            } else {
                status.textContent = 'Camera API not supported on this device or browser';
            }
            
            status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
            return;
        }
        
        console.log("Camera supported, requesting access...");
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: {
                width: { ideal: 640 },
                height: { ideal: 480 },
                facingMode: 'user'
            }
        });
        
        console.log("Camera access granted, attaching to video element...");
        video.srcObject = stream;
        
        // Wait for video to be properly loaded before proceeding
        await new Promise((resolve) => {
            video.onloadedmetadata = () => {
                console.log("Video metadata loaded");
                video.play();
                resolve();
            };
        });
        
        // Additional delay to ensure video is fully initialized
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        console.log("Video dimensions:", video.videoWidth, video.videoHeight);
        status.textContent = 'Camera initialized. Please look at the camera.';
        status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
        
        // Start face detection after ensuring video is ready
        startFaceDetection();
    } catch (error) {
        console.error('Camera error:', error);
        status.textContent = 'Error: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
    }
}

async function startFaceDetection() {
    try {
        // Check if video is ready
        if (!video.videoWidth || !video.videoHeight) {
            console.log("Video not ready yet, dimensions:", video.videoWidth, video.videoHeight);
            status.textContent = 'Waiting for camera to fully initialize...';
            // Wait a bit and retry
            setTimeout(startFaceDetection, 500);
            return;
        }
        
        console.log("Creating canvas for face detection, video dimensions:", video.videoWidth, video.videoHeight);
        const canvas = document.createElement('canvas');
    canvas.id = 'overlay';
        canvas.className = 'absolute top-0 left-0';
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        console.log("Replacing canvas overlay");
        const existingOverlay = document.getElementById('overlay');
        existingOverlay.parentNode.replaceChild(canvas, existingOverlay);
        
        console.log("Setting up face detection interval");
    faceCheckInterval = setInterval(async () => {
            try {
        const detection = await detectFace(video);
        if (detection) {
                    console.log("Face detected");
            drawFaceDetections(video, canvas, detection);
                    captureButton.disabled = false;
                    status.textContent = 'Face detected. Proceed to mark attendance.';
            status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
        } else {
                    console.log("No face detected");
            canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
            captureButton.disabled = true;
            status.textContent = 'No face detected. Please position your face in the camera.';
            status.className = 'text-center text-lg mb-4 p-2 bg-yellow-100 text-yellow-700';
                }
            } catch (error) {
                console.error("Error in face detection interval:", error);
        }
    }, 100);
    } catch (error) {
        console.error("Error in startFaceDetection:", error);
        status.textContent = 'Error starting face detection: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
    }
}

async function markAttendance() {
    if (isProcessing) return;
    isProcessing = true;
    
    try {
        status.textContent = 'Attempting face recognition...';
        
        const detection = await detectFace(video);
        console.log('Detection result:', detection);
        
        if (!detection) {
            throw new Error('No face detected');
        }

        // Get location
        const position = await new Promise((resolve, reject) => {
            navigator.geolocation.getCurrentPosition(resolve, reject);
        });

        status.textContent = 'Sending attendance data...';

        const response = await fetch('/api/mark-attendance', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': '{{ csrf_token() }}'
            },
            body: JSON.stringify({
                session_id: "{{ session.id }}",
                face_descriptor: Array.from(detection.descriptor),
                latitude: position.coords.latitude,
                longitude: position.coords.longitude
            })
        });

        if (!response.ok) {
            const errorText = await response.text();
            if( errorText['error'] == "No matching student found")
            {
                 // Display success message with student name
                status.textContent = `No matching student found!`;
                status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
                console.log("No student found.")
            }else{
                throw new Error(`Server error: ${response.status}`);
            }
            console.error('Server response:', errorText);
        }

        // Parse the JSON response
        const result = await response.json();
        if(result["error"] == "`No matching student found")
        console.log('Attendance result:', result);
        
        // Display success message with student name
        status.textContent = `Attendance marked successfully for ${result.student_name}!`;
        status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
        
        // Stop camera
        clearInterval(faceCheckInterval);
        video.srcObject.getTracks().forEach(track => track.stop());
        
        // Redirect after 2 seconds
        setTimeout(() => {
            window.location.href = `/attendance/success/${result.student_name}`;
        }, 2000);

    } catch (error) {
        console.error('Error:', error);
        status.textContent = 'Error: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
    } finally {
        isProcessing = false;
    }
}

// Initialize
document.addEventListener('DOMContentLoaded', async () => {
    status.textContent = 'Loading face recognition models...';
    const modelsLoaded = await loadModels();
    if (modelsLoaded) {
        startButton.disabled = false;
        status.textContent = 'Ready to start. Click "Start Camera"';
    }
});

startButton.addEventListener('click', startCamera);
captureButton.addEventListener('click', markAttendance);
</script>
{% endblock %} 