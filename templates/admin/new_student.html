{% extends "base.html" %}

{% block title %}Add New Student - Attendance System{% endblock %}

{% block content %}
<div class="max-w-2xl mx-auto bg-white shadow rounded-lg p-6">
    <h2 class="text-2xl font-bold mb-6">Add New Student</h2>
    
    <form id="studentForm" class="space-y-4">
        <div>
            <label class="block text-sm font-medium text-gray-700">Student ID</label>
            <input type="text" name="student_id" required 
                   pattern="[0-9]{10}" 
                   title="Please enter a valid 10-digit student ID"
                   class="mt-1 block w-full rounded-md border-gray-300 shadow-sm">
        </div>
        
        <div>
            <label class="block text-sm font-medium text-gray-700">Name</label>
            <input type="text" name="name" required class="mt-1 block w-full rounded-md border-gray-300 shadow-sm">
        </div>
        
        <input type="hidden" name="face_descriptor" id="faceDescriptor">
        
        <div class="flex justify-center space-x-4 mt-4">
            <button type="button" id="readyButton" class="bg-green-500 text-white px-4 py-2 rounded">
                Ready
            </button>
        </div>
    </form>
    
    <div class="relative mt-6" style="width: 640px; height: 480px; margin: 0 auto;">
        <video id="video" width="640" height="480" autoplay muted class="mx-auto border rounded-lg"></video>
        <canvas id="overlay" class="absolute top-0 left-0" width="640" height="480"></canvas>
    </div>
    
    <div id="status" class="text-center text-lg mb-4 p-2"></div>
</div>

<script src="{{ url_for('static', filename='js/face-recognition.js') }}"></script>
<script>
const video = document.getElementById('video');
const overlay = document.getElementById('overlay');
const status = document.getElementById('status');
const form = document.getElementById('studentForm');
const readyButton = document.getElementById('readyButton');

let faceCheckInterval;

readyButton.addEventListener('click', () => {
    status.textContent = 'Loading face recognition models...';
    loadModels().then(modelsLoaded => {
        if (modelsLoaded) {
            status.textContent = 'Ready to start. Initializing camera...';
            status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
            initializeCamera();
        } else {
            status.textContent = 'Error loading models. Please try again.';
            status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
        }
    });
});

async function initializeCamera() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: {
                width: 640,
                height: 480,
                facingMode: 'user'
            }
        });
        video.srcObject = stream;
        status.textContent = 'Camera initialized. Please look at the camera.';
        status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
        
        // Start face detection after camera is initialized
        video.addEventListener('play', startFaceDetection);
    } catch (error) {
        status.textContent = 'Error accessing camera: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
    }
}

async function startFaceDetection() {
    try {
        const canvas = document.createElement('canvas');
        canvas.id = 'overlay';
        canvas.className = 'absolute top-0 left-0';
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        const existingOverlay = document.getElementById('overlay');
        existingOverlay.parentNode.replaceChild(canvas, existingOverlay);

        faceCheckInterval = setInterval(async () => {
            try {
                const result = await detectFace(video);
                if (result && result.detection) {  // Check for detection
                    console.log("Face detected with descriptor");
                    const ctx = canvas.getContext('2d');
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    drawFaceDetections(video, canvas, result.detection);
                    status.textContent = 'Face detected. Capturing...';
                    status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';

                    // Automatically capture face after 1 second
                    clearInterval(faceCheckInterval); // Stop further detection
                    setTimeout(() => {
                        captureFace(result.detection);
                    }, 1000);
                } else {
                    console.log("No face detected or no descriptor available");
                    const ctx = canvas.getContext('2d');
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    status.textContent = 'No face detected. Please position your face in the camera.';
                    status.className = 'text-center text-lg mb-4 p-2 bg-yellow-100 text-yellow-700';
                }
            } catch (error) {
                console.error("Error in face detection interval:", error);
                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                status.textContent = 'Error detecting face. Please try again.';
                status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
            }
        }, 100);
    } catch (error) {
        console.error("Error in startFaceDetection:", error);
        status.textContent = 'Error starting face detection: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
    }
}

async function captureFace(detection) {
    try {
        status.textContent = 'Capturing face data (please stay still)...';
        status.className = 'text-center text-lg mb-4 p-2 bg-yellow-100 text-yellow-700';

        // Use the descriptor from the detection directly if available
        let faceDescriptor;
        if (detection && detection.descriptor) {
            faceDescriptor = detection.descriptor;
        } else {
            // Fallback to getting average descriptor
            faceDescriptor = await getAverageFaceDescriptor(video);
        }
        
        if (!faceDescriptor) {
            throw new Error('Could not get a valid face descriptor. Please try again.');
        }

        // Convert descriptor to array if it isn't already
        const descriptorArray = Array.isArray(faceDescriptor) ? faceDescriptor : Array.from(faceDescriptor);

        if (descriptorArray.length === 0) {
            throw new Error('Face descriptor is empty. Please try again.');
        }

        document.getElementById('faceDescriptor').value = JSON.stringify(descriptorArray);
        status.textContent = 'Face captured! Saving student...';
        status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';

        // Use AJAX to submit the form data
        const formData = new FormData(form);
        const response = await fetch('/admin/students/new', {
            method: 'POST',
            headers: {
                'X-CSRFToken': '{{ csrf_token() }}'
            },
            body: formData
        });

        const result = await response.json();
        if (result.success) {
            status.textContent = 'Student saved successfully!';
            status.className = 'text-center text-lg mb-4 p-2 bg-green-100 text-green-700';
            setTimeout(() => {
                window.location.href = '/admin';
            }, 2000);
        } else {
            throw new Error(result.error || 'Failed to save student');
        }
    } catch (error) {
        console.error('Error capturing face:', error);
        status.textContent = 'Error: ' + error.message;
        status.className = 'text-center text-lg mb-4 p-2 bg-red-100 text-red-700';
        
        // Reset the detection process so user can try again
        setTimeout(() => {
            status.textContent = 'Please try again';
            startFaceDetection();
        }, 2000);
    }
}
</script>
{% endblock %} 